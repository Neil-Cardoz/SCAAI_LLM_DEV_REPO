{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW0Ug5ZoHdUuebe+e/ml/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neil-Cardoz/SCAAI_LLM_DEV_REPO/blob/main/SCAAI_FIRECRAWL_TRY2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54YptnXlTSGu",
        "outputId": "7888af6f-2352-4b89-ffe4-3d97766294a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting firecrawl-py\n",
            "  Downloading firecrawl_py-4.3.6-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (2.32.4)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (0.28.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (1.1.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (15.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (2.11.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from firecrawl-py) (3.12.15)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->firecrawl-py) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->firecrawl-py) (1.20.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->firecrawl-py) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->firecrawl-py) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->firecrawl-py) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->firecrawl-py) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->firecrawl-py) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->firecrawl-py) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->firecrawl-py) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->firecrawl-py) (1.3.1)\n",
            "Downloading firecrawl_py-4.3.6-py3-none-any.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m168.7/168.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: firecrawl-py\n",
            "Successfully installed firecrawl-py-4.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install firecrawl-py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from firecrawl import Firecrawl\n",
        "\n",
        "firecrawl = Firecrawl(api_key=\"fc-23eda15af3bc485499b2afc562b3b40b\")\n",
        "\n",
        "# Scrape a website (returns a Document)\n",
        "doc = firecrawl.scrape(\n",
        "    \"https://firecrawl.dev\",\n",
        "    formats=[\"markdown\", \"html\"],\n",
        ")\n",
        "print(doc.markdown)\n",
        "\n",
        "# Crawl a website\n",
        "response = firecrawl.crawl(\n",
        "    \"https://firecrawl.dev\",\n",
        "    limit=100,\n",
        "    scrape_options={\"formats\": \"markdown\"},\n",
        "    poll_interval=30,\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kxluy9xDTTcZ",
        "outputId": "558e10cd-8f12-4206-fafd-11e104ead4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We just raised our Series A and shipped Firecrawl /v2 üéâ. [Read the blog.](https://www.firecrawl.dev/blog/firecrawl-v2-series-a-announcement)\n",
            "\n",
            "[2 Months Free ‚Äî Annually](https://www.firecrawl.dev/pricing)\n",
            "\n",
            "# Turn websites into   LLM-ready data\n",
            "\n",
            "Power your AI apps with clean data crawled\n",
            "\n",
            "from any website. [It's also open source.](https://github.com/firecrawl/firecrawl)\n",
            "\n",
            "Scrape\n",
            "\n",
            "Search\n",
            "New\n",
            "\n",
            "Map\n",
            "\n",
            "Crawl\n",
            "\n",
            "Scrape\n",
            "\n",
            "\\[ .JSON \\]\n",
            "\n",
            "```json\n",
            "1[\\\n",
            "2  {\\\n",
            "3    \"url\": \"h=t*A:!/z!aap?A-cZz\",\\\n",
            "4    \"markdown\": \"# ?0z-ang S*a-Z-a0*9\",\\\n",
            "5    \"json\": { \"title\": \"G!=*?\", \"docs\": \"...\" },\\\n",
            "6    \"screenshot\": \"ht-=*:/?*Za!zl=-?a9?h0-!.png\"\\\n",
            "7  }\\\n",
            "8]\n",
            "```\n",
            "\n",
            "Scraping...\n",
            "\n",
            "Trusted by5000+\n",
            "\n",
            "companiesof all sizes\n",
            "\n",
            "![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)\n",
            "\n",
            "![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)\n",
            "\n",
            "![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)\n",
            "\n",
            "![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)\n",
            "\n",
            "![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)\n",
            "\n",
            "![Logo 4](https://www.firecrawl.dev/assets-original/logocloud/4.png)\n",
            "\n",
            "![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)\n",
            "\n",
            "![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)\n",
            "\n",
            "![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)\n",
            "\n",
            "![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)\n",
            "\n",
            "![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)\n",
            "\n",
            "![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)\n",
            "\n",
            "![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)\n",
            "\n",
            "![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)\n",
            "\n",
            "![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)\n",
            "\n",
            "![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)\n",
            "\n",
            "![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)\n",
            "\n",
            "![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)\n",
            "\n",
            "![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)\n",
            "\n",
            "![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)\n",
            "\n",
            "![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)\n",
            "\n",
            "![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)\n",
            "\n",
            "![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)\n",
            "\n",
            "![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)\n",
            "\n",
            "![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)\n",
            "\n",
            "![Logo 1](https://www.firecrawl.dev/assets-original/logocloud/1.png)\n",
            "\n",
            "![Logo 2](https://www.firecrawl.dev/assets-original/logocloud/2.png)\n",
            "\n",
            "![Logo 3](https://www.firecrawl.dev/assets-original/logocloud/3.png)\n",
            "\n",
            "![Logo 4](https://www.firecrawl.dev/assets-original/logocloud/4.png)\n",
            "\n",
            "![Logo 5](https://www.firecrawl.dev/assets-original/logocloud/5.png)\n",
            "\n",
            "![Logo 6](https://www.firecrawl.dev/assets-original/logocloud/6.png)\n",
            "\n",
            "![Logo 7](https://www.firecrawl.dev/assets-original/logocloud/7.png)\n",
            "\n",
            "![Logo 8](https://www.firecrawl.dev/assets-original/logocloud/8.png)\n",
            "\n",
            "![Logo 9](https://www.firecrawl.dev/assets-original/logocloud/9.png)\n",
            "\n",
            "![Logo 10](https://www.firecrawl.dev/assets-original/logocloud/10.png)\n",
            "\n",
            "![Logo 11](https://www.firecrawl.dev/assets-original/logocloud/11.png)\n",
            "\n",
            "![Logo 12](https://www.firecrawl.dev/assets-original/logocloud/12.png)\n",
            "\n",
            "![Logo 13](https://www.firecrawl.dev/assets-original/logocloud/13.png)\n",
            "\n",
            "![Logo 14](https://www.firecrawl.dev/assets-original/logocloud/14.png)\n",
            "\n",
            "![Logo 15](https://www.firecrawl.dev/assets-original/logocloud/15.png)\n",
            "\n",
            "![Logo 16](https://www.firecrawl.dev/assets-original/logocloud/16.png)\n",
            "\n",
            "![Logo 17](https://www.firecrawl.dev/assets-original/logocloud/17.png)\n",
            "\n",
            "![Logo 18](https://www.firecrawl.dev/assets-original/logocloud/18.png)\n",
            "\n",
            "![Logo 19](https://www.firecrawl.dev/assets-original/logocloud/19.png)\n",
            "\n",
            "![Logo 20](https://www.firecrawl.dev/assets-original/logocloud/20.png)\n",
            "\n",
            "![Logo 21](https://www.firecrawl.dev/assets-original/logocloud/21.png)\n",
            "\n",
            "\\[01/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Main Features\n",
            "\n",
            "//\n",
            "\n",
            "Developer First\n",
            "\n",
            "//\n",
            "\n",
            "## Startscraping   today\n",
            "\n",
            "Enhance your apps with industry leading web scraping and crawling capabilities.\n",
            "\n",
            "Scrape\n",
            "\n",
            "Get llm-ready data from websites. Markdown, JSON, screenshot, etc.\n",
            "\n",
            "Search\n",
            "\n",
            "New\n",
            "\n",
            "Search the web and get full content from results.\n",
            "\n",
            "Crawl\n",
            "\n",
            "Crawl all the pages on a website and get data for each page.\n",
            "\n",
            "Python\n",
            "\n",
            "Node.js\n",
            "\n",
            "Curl\n",
            "\n",
            "Copy code\n",
            "\n",
            "```python\n",
            "1# pip install firecrawl-py\n",
            "2from firecrawl import Firecrawl\n",
            "3\n",
            "4app = Firecrawl(api_key=\"fc-YOUR_API_KEY\")\n",
            "5\n",
            "6# Scrape a website:\n",
            "7app.scrape('firecrawl.dev')\n",
            "8\n",
            "9\n",
            "10\n",
            "```\n",
            "\n",
            "\\[ .MD \\]\n",
            "\n",
            "```markdown\n",
            "1# Firecrawl\n",
            "2\n",
            "3Firecrawl is a powerful web scraping\n",
            "4library that makes it easy to extract\n",
            "5data from websites.\n",
            "6\n",
            "7## Installation\n",
            "8\n",
            "9To install Firecrawl, run:\n",
            "10\n",
            "11\n",
            "```\n",
            "\n",
            "![developer-1](https://www.firecrawl.dev/assets/developer/1.png)\n",
            "\n",
            "![developer-2](https://www.firecrawl.dev/assets/developer/2.png)\n",
            "\n",
            "![developer-3](https://www.firecrawl.dev/assets/developer/3.png)\n",
            "\n",
            "![developer-4](https://www.firecrawl.dev/assets/developer/4.png)\n",
            "\n",
            "![developer-5](https://www.firecrawl.dev/assets/developer/5.png)\n",
            "\n",
            "![developer-6](https://www.firecrawl.dev/assets/developer/6.png)\n",
            "\n",
            "![developer-7](https://www.firecrawl.dev/assets/developer/7.png)\n",
            "\n",
            "![developer-8](https://www.firecrawl.dev/assets/developer/8.png)\n",
            "\n",
            "![developer-9](https://www.firecrawl.dev/assets/developer/1.png)\n",
            "\n",
            "![developer-10](https://www.firecrawl.dev/assets/developer/2.png)\n",
            "\n",
            "![developer-11](https://www.firecrawl.dev/assets/developer/3.png)\n",
            "\n",
            "![developer-12](https://www.firecrawl.dev/assets/developer/4.png)\n",
            "\n",
            "![developer-13](https://www.firecrawl.dev/assets/developer/5.png)\n",
            "\n",
            "![developer-14](https://www.firecrawl.dev/assets/developer/6.png)\n",
            "\n",
            "![developer-15](https://www.firecrawl.dev/assets/developer/7.png)\n",
            "\n",
            "![developer-16](https://www.firecrawl.dev/assets/developer/8.png)\n",
            "\n",
            "![developer-17](https://www.firecrawl.dev/assets/developer/1.png)\n",
            "\n",
            "![developer-18](https://www.firecrawl.dev/assets/developer/2.png)\n",
            "\n",
            "![developer-19](https://www.firecrawl.dev/assets/developer/3.png)\n",
            "\n",
            "![developer-20](https://www.firecrawl.dev/assets/developer/4.png)\n",
            "\n",
            "![developer-21](https://www.firecrawl.dev/assets/developer/5.png)\n",
            "\n",
            "![developer-22](https://www.firecrawl.dev/assets/developer/6.png)\n",
            "\n",
            "![developer-23](https://www.firecrawl.dev/assets/developer/7.png)\n",
            "\n",
            "![developer-24](https://www.firecrawl.dev/assets/developer/8.png)\n",
            "\n",
            "Integrations\n",
            "\n",
            "### Use well-known tools\n",
            "\n",
            "Already fully integrated with the greatest existing tools and workflows.\n",
            "\n",
            "[See all integrations](https://www.firecrawl.dev/app)\n",
            "\n",
            "![Firecrawl icon (blueprint)](https://www.firecrawl.dev/assets-original/developer-os-icon.png)\n",
            "\n",
            "mendableai/firecrawl\n",
            "\n",
            "Public\n",
            "\n",
            "Star\n",
            "\n",
            "57.5K\n",
            "\n",
            "\\[python-SDK\\] improvs/async\n",
            "\n",
            "#1337\n",
            "\n",
            "¬∑\n",
            "\n",
            "Apr 18, 2025\n",
            "\n",
            "¬∑\n",
            "\n",
            "![rafaelsideguide](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=48&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "rafaelsideguide\n",
            "\n",
            "feat(extract): cost limit\n",
            "\n",
            "#1473\n",
            "\n",
            "¬∑\n",
            "\n",
            "Apr 17, 2025\n",
            "\n",
            "¬∑\n",
            "\n",
            "![mogery](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=48&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "mogery\n",
            "\n",
            "feat(scrape): get job result from GCS, avoid Redis\n",
            "\n",
            "#1461\n",
            "\n",
            "¬∑\n",
            "\n",
            "Apr 15, 2025\n",
            "\n",
            "¬∑\n",
            "\n",
            "![mogery](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=48&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "mogery\n",
            "\n",
            "Extract v2/rerank improvs\n",
            "\n",
            "#1437\n",
            "\n",
            "¬∑\n",
            "\n",
            "Apr 11, 2025\n",
            "\n",
            "¬∑\n",
            "\n",
            "![rafaelsideguide](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=48&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "rafaelsideguide\n",
            "\n",
            "![https://avatars.githubusercontent.com/u/150964962?v=4](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F150964962%3Fv%3D4&w=96&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "![https://avatars.githubusercontent.com/u/66118807?v=4](https://www.firecrawl.dev/_next/image?url=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F66118807%3Fv%3D4&w=96&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "+90\n",
            "\n",
            "Open Source\n",
            "\n",
            "### Code you can trust\n",
            "\n",
            "Developed transparently and collaboratively. Join our community of contributors.\n",
            "\n",
            "[Check out our repo](https://github.com/firecrawl/firecrawl)\n",
            "\n",
            "\\[02/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Core\n",
            "\n",
            "//\n",
            "\n",
            "Built to outperform\n",
            "\n",
            "//\n",
            "\n",
            "## Core principles,    provenperformance\n",
            "\n",
            "Built from the ground up to outperform traditional scrapers.\n",
            "\n",
            "No proxy headaches\n",
            "\n",
            "Reliable.Covers 96% of the web,\n",
            "\n",
            "including JS-heavy and protected pages. No proxies, no puppets, just clean data.\n",
            "\n",
            "Firecrawl\n",
            "\n",
            "0%\n",
            "\n",
            "![Puppeteer icon](https://www.firecrawl.dev/assets/puppeteer.png)\n",
            "\n",
            "Puppeteer\n",
            "\n",
            "0%\n",
            "\n",
            "cURL\n",
            "\n",
            "0%\n",
            "\n",
            "Speed that feels invisible\n",
            "\n",
            "Blazingly fast.Delivers results in less than 1 second, fast for real-time agents\n",
            "\n",
            "and dynamic apps.\n",
            "\n",
            "URL\n",
            "\n",
            "Crawl\n",
            "\n",
            "Scrape\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "0ms\n",
            "\n",
            "\\[03/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Features\n",
            "\n",
            "//\n",
            "\n",
            "Zero configuration\n",
            "\n",
            "//\n",
            "\n",
            "## We handle the hard stuff\n",
            "\n",
            "Rotating proxies, orchestration, rate limits, js-blocked content and more.\n",
            "\n",
            "Docs to data\n",
            "\n",
            "Media parsing.Firecrawl can parse and output content from web hosted pdfs, docx, and more.\n",
            "\n",
            "https://example.com/docs/report.pdf\n",
            "\n",
            "https://example.com/files/brief.docx\n",
            "\n",
            "https://example.com/docs/guide.html\n",
            "\n",
            "docx\n",
            "\n",
            "Parsing...\n",
            "\n",
            "Knows the moment\n",
            "\n",
            "Smart wait.Firecrawl intelligently waits for content to load, making scraping faster and more reliable.\n",
            "\n",
            "https://example-spa.com\n",
            "\n",
            "Request Sent\n",
            "\n",
            "Scrapes the real thing\n",
            "\n",
            "Cached, when you need it.Selective caching, you choose your caching patterns, growing web index.\n",
            "\n",
            "![User](https://www.firecrawl.dev/_next/image?url=%2Fassets-original%2Ffeatures%2Fcached-user.png&w=256&q=75&dpl=dpl_HiKvUaET1fMpDSsDawemrK3DsCV6)\n",
            "\n",
            "User\n",
            "\n",
            "Firecrawl\n",
            "\n",
            "Cache & Web\n",
            "\n",
            "Invisible access\n",
            "\n",
            "Stealth mode.Crawls the web without\n",
            "\n",
            "being blocked, mimics real users to access protected or dynamic content.\n",
            "\n",
            "Interactive scraping\n",
            "\n",
            "Actions.Click, scroll, write, wait, press and more before extracting content.\n",
            "\n",
            "https://example.com\n",
            "\n",
            "Navigate\n",
            "\n",
            "Click\n",
            "\n",
            "Type\n",
            "\n",
            "Wait\n",
            "\n",
            "Scroll\n",
            "\n",
            "Press\n",
            "\n",
            "Screenshot\n",
            "\n",
            "Scrape\n",
            "\n",
            "\\[04/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Pricing\n",
            "\n",
            "Loading pricing...\n",
            "\n",
            "\\[05/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Testimonials\n",
            "\n",
            "//\n",
            "\n",
            "Community\n",
            "\n",
            "//\n",
            "\n",
            "## People love    building withFirecrawl\n",
            "\n",
            "Discover why developers choose Firecrawl every day.\n",
            "\n",
            "[![Morgan Linton](https://www.firecrawl.dev/assets/testimonials/morgan-linton.png)Morgan Linton@morganlinton\"If you're coding with AI, and haven't discovered @firecrawl\\_dev yet, prepare to have your mind blown ü§Ø\"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\\_\"Started using @firecrawl\\_dev for a project, I wish I used this sooner.\"](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets/testimonials/alex-reibman.png)Alex Reibman@AlexReibman\"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\"](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin\"I found gold today. Thank you @firecrawl\\_dev\"](https://x.com/TomReppelin/status/1844382491014201613)\n",
            "\n",
            "[![Morgan Linton](https://www.firecrawl.dev/assets/testimonials/morgan-linton.png)Morgan Linton@morganlinton\"If you're coding with AI, and haven't discovered @firecrawl\\_dev yet, prepare to have your mind blown ü§Ø\"](https://x.com/morganlinton/status/1839454165703204955) [![Chris DeWeese](https://www.firecrawl.dev/assets/testimonials/chris-deweese.png)Chris DeWeese@chrisdeweese\\_\"Started using @firecrawl\\_dev for a project, I wish I used this sooner.\"](https://x.com/chrisdeweese_/status/1853587120406876601) [![Alex Reibman](https://www.firecrawl.dev/assets/testimonials/alex-reibman.png)Alex Reibman@AlexReibman\"Moved our internal agent's web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\"](https://x.com/AlexReibman/status/1780299595484131836) [![Tom - Morpho](https://www.firecrawl.dev/assets/testimonials/tom-morpho.png)Tom - Morpho@TomReppelin\"I found gold today. Thank you @firecrawl\\_dev\"](https://x.com/TomReppelin/status/1844382491014201613)\n",
            "\n",
            "[![Bardia](https://www.firecrawl.dev/assets/testimonials/bardia.png)Bardia@thepericulum\"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them.\"](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets/testimonials/matt-busigin.png)Matt Busigin@mbusigin\"Firecrawl is dope. Congrats guys üëè\"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets/testimonials/sumanth.png)Sumanth@Sumanth\\_077\"Web scraping will never be the same!\\\\\n",
            "\\\\\n",
            "Firecrawl is an open-source framework that takes a URL, crawls it, and conver...\"](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets/testimonials/steven-tey.png)Steven Tey@steventey\"Open-source Clay alternative just dropped\\\\\n",
            "\\\\\n",
            "Upload a CSV of emails and...\"](https://x.com/steventey/status/1932945651761098889)\n",
            "\n",
            "[![Bardia](https://www.firecrawl.dev/assets/testimonials/bardia.png)Bardia@thepericulum\"The Firecrawl team ships. I wanted types for their node SDK, and less than an hour later, I got them.\"](https://x.com/thepericulum/status/1781397799487078874) [![Matt Busigin](https://www.firecrawl.dev/assets/testimonials/matt-busigin.png)Matt Busigin@mbusigin\"Firecrawl is dope. Congrats guys üëè\"](https://x.com/mbusigin/status/1836065372010656069) [![Sumanth](https://www.firecrawl.dev/assets/testimonials/sumanth.png)Sumanth@Sumanth\\_077\"Web scraping will never be the same!\\\\\n",
            "\\\\\n",
            "Firecrawl is an open-source framework that takes a URL, crawls it, and conver...\"](https://x.com/Sumanth_077/status/1940049003074478511) [![Steven Tey](https://www.firecrawl.dev/assets/testimonials/steven-tey.png)Steven Tey@steventey\"Open-source Clay alternative just dropped\\\\\n",
            "\\\\\n",
            "Upload a CSV of emails and...\"](https://x.com/steventey/status/1932945651761098889)\n",
            "\n",
            "\\[06/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "Use Cases\n",
            "\n",
            "//\n",
            "\n",
            "Use cases\n",
            "\n",
            "//\n",
            "\n",
            "## Transform    web data into  AI-powered solutions\n",
            "\n",
            "Discover how Firecrawl customers are getting the most out of our API.\n",
            "\n",
            "[View all use cases](https://docs.firecrawl.dev/use-cases/overview)\n",
            "\n",
            "Chat with context\n",
            "\n",
            "Smarter AI chats\n",
            "\n",
            "Power your AI assistants with real-time, accurate web content.\n",
            "\n",
            "[View docs](https://docs.firecrawl.dev/introduction)\n",
            "\n",
            "![AI Assistant](https://www.firecrawl.dev/assets/ai/bot.png)\n",
            "\n",
            "AI Assistant\n",
            "\n",
            "withFirecrawl\n",
            "\n",
            "Real-time¬∑Updated 2 min ago\n",
            "\n",
            "Know your leads\n",
            "\n",
            "Lead enrichment\n",
            "\n",
            "Enhance your sales data with\n",
            "\n",
            "web information.\n",
            "\n",
            "[Check out Extract](https://www.firecrawl.dev/extract)\n",
            "\n",
            "Extracting leads from directory...\n",
            "\n",
            "Tech startups\n",
            "\n",
            "With contact info\n",
            "\n",
            "Decision makers\n",
            "\n",
            "Funding stage\n",
            "\n",
            "Ready to engage\n",
            "\n",
            "![Emily Tran](https://www.firecrawl.dev/assets/ai/leads-1.png)\n",
            "\n",
            "![James Carter](https://www.firecrawl.dev/assets/ai/leads-2.png)\n",
            "\n",
            "![Sophia Kim](https://www.firecrawl.dev/assets/ai/leads-3.png)\n",
            "\n",
            "![Michael Rivera](https://www.firecrawl.dev/assets/ai/leads-4.png)\n",
            "\n",
            "Know your leads\n",
            "\n",
            "MCPs\n",
            "\n",
            "Add powerful scraping to your\n",
            "\n",
            "code editors.\n",
            "\n",
            "[Get started](https://docs.firecrawl.dev/mcp-server)\n",
            "\n",
            "![Claude Code](https://www.firecrawl.dev/assets/ai/mcps-claude.png)\n",
            "\n",
            "Claude Code\n",
            "\n",
            "![Cursor](https://www.firecrawl.dev/assets/ai/mcps-cursor.png)\n",
            "\n",
            "Cursor\n",
            "\n",
            "![Windsurf](https://www.firecrawl.dev/assets/ai/mcps-windsurf.png)\n",
            "\n",
            "Windsurf\n",
            "\n",
            "‚úª\n",
            "\n",
            "Welcome to Claude Code!\n",
            "\n",
            "/help for help, /status for your current setup\n",
            "\n",
            ">Try \"how do I log an error?\"\n",
            "\n",
            "Build with context\n",
            "\n",
            "AI platforms\n",
            "\n",
            "Let your customers build AI apps\n",
            "\n",
            "with web data.\n",
            "\n",
            "[Check out Map](https://docs.firecrawl.dev/features/map)\n",
            "\n",
            "![Logo 1](https://www.firecrawl.dev/assets/ai/platforms-1.png)\n",
            "\n",
            "![Logo 2](https://www.firecrawl.dev/assets/ai/platforms-2.png)\n",
            "\n",
            "![Logo 4](https://www.firecrawl.dev/assets/ai/platforms-4.png)\n",
            "\n",
            "![Logo 3](https://www.firecrawl.dev/assets/ai/platforms-3.png)\n",
            "\n",
            "Extracting text...\n",
            "\n",
            "No insight missed\n",
            "\n",
            "Deep research\n",
            "\n",
            "Extract comprehensive information for\n",
            "\n",
            "in-depth research.\n",
            "\n",
            "[Build your own with Search](https://docs.firecrawl.dev/features/search)\n",
            "\n",
            "Deep research in progress...\n",
            "\n",
            "Academic papers\n",
            "\n",
            "0 found\n",
            "\n",
            "News articles\n",
            "\n",
            "0 found\n",
            "\n",
            "Expert opinions\n",
            "\n",
            "0 found\n",
            "\n",
            "Research reports\n",
            "\n",
            "0 found\n",
            "\n",
            "Industry data\n",
            "\n",
            "0 found\n",
            "\n",
            "Ask anything...\n",
            "\n",
            "\\[07/ 07 \\]\n",
            "\n",
            "¬∑\n",
            "\n",
            "FAQ\n",
            "\n",
            "//\n",
            "\n",
            "FAQ\n",
            "\n",
            "//\n",
            "\n",
            "## Frequently    askedquestions\n",
            "\n",
            "Everything you need to know about Firecrawl.\n",
            "\n",
            "General\n",
            "\n",
            "What is Firecrawl?\n",
            "\n",
            "What sites work?\n",
            "\n",
            "Who can benefit from using Firecrawl?\n",
            "\n",
            "Is Firecrawl open-source?\n",
            "\n",
            "What is the difference between Firecrawl and other web scrapers?\n",
            "\n",
            "What is the difference between the open-source version and the hosted version?\n",
            "\n",
            "Scraping & Crawling\n",
            "\n",
            "How does Firecrawl handle dynamic content on websites?\n",
            "\n",
            "Why is it not crawling all the pages?\n",
            "\n",
            "Can Firecrawl crawl websites without a sitemap?\n",
            "\n",
            "What formats can Firecrawl convert web data into?\n",
            "\n",
            "How does Firecrawl ensure the cleanliness of the data?\n",
            "\n",
            "Is Firecrawl suitable for large-scale data scraping projects?\n",
            "\n",
            "Does it respect robots.txt?\n",
            "\n",
            "What measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\n",
            "\n",
            "Does Firecrawl handle captcha or authentication?\n",
            "\n",
            "API Related\n",
            "\n",
            "Where can I find my API key?\n",
            "\n",
            "Billing\n",
            "\n",
            "Is Firecrawl free?\n",
            "\n",
            "Is there a pay-per-use plan instead of monthly?\n",
            "\n",
            "Do credits roll over to the next month?\n",
            "\n",
            "How many credits do scraping and crawling cost?\n",
            "\n",
            "Do you charge for failed requests?\n",
            "\n",
            "What payment methods do you accept?\n",
            "\n",
            "FOOTER\n",
            "\n",
            "The easiest way to extract\n",
            "\n",
            "data from the web\n",
            "\n",
            "Backed by\n",
            "\n",
            "Y Combinator\n",
            "\n",
            "[Linkedin](https://www.linkedin.com/company/firecrawl) [Github](https://github.com/firecrawl/firecrawl)\n",
            "\n",
            "SOC II ¬∑ Type 2\n",
            "\n",
            "AICPA\n",
            "\n",
            "SOC 2\n",
            "\n",
            "[X (Twitter)](https://x.com/firecrawl_dev) [Discord](https://discord.gg/gSmWdAkdwd)\n",
            "\n",
            "Products\n",
            "\n",
            "[Playground](https://www.firecrawl.dev/playground) [Extract](https://www.firecrawl.dev/extract) [Pricing](https://www.firecrawl.dev/pricing) [Templates](https://www.firecrawl.dev/templates) [Changelog](https://www.firecrawl.dev/changelog)\n",
            "\n",
            "Use Cases\n",
            "\n",
            "[AI Platforms](https://docs.firecrawl.dev/use-cases/ai-platforms) [Lead Enrichment](https://docs.firecrawl.dev/use-cases/lead-enrichment) [SEO Platforms](https://docs.firecrawl.dev/use-cases/seo-platforms) [Deep Research](https://docs.firecrawl.dev/use-cases/deep-research)\n",
            "\n",
            "Documentation\n",
            "\n",
            "[Getting started](https://docs.firecrawl.dev/introduction) [API Reference](https://docs.firecrawl.dev/api-reference/introduction) [Integrations](https://www.firecrawl.dev/app) [Examples](https://docs.firecrawl.dev/use-cases/overview) [SDKs](https://docs.firecrawl.dev/sdks/overview)\n",
            "\n",
            "Company\n",
            "\n",
            "[Blog](https://www.firecrawl.dev/blog) [Careers](https://www.firecrawl.dev/careers) [Creator & OSS program](https://www.firecrawl.dev/creator-oss-program) [Student program](https://www.firecrawl.dev/student-program)\n",
            "\n",
            "¬© 2025 Firecrawl\n",
            "\n",
            "[Terms of Service](https://www.firecrawl.dev/terms-of-service) [Privacy Policy](https://www.firecrawl.dev/privacy-policy) [Report Abuse](mailto:help@firecrawl.com?subject=Issue:)\n",
            "\n",
            "[Loading status...](https://firecrawl.betteruptime.com/)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-375968592.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Crawl a website\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m response = firecrawl.crawl(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"https://firecrawl.dev\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/client.py\u001b[0m in \u001b[0;36mcrawl\u001b[0;34m(self, url, prompt, exclude_paths, include_paths, max_discovery_depth, ignore_sitemap, ignore_query_parameters, limit, crawl_entire_domain, allow_external_links, allow_subdomains, delay, max_concurrency, webhook, scrape_options, zero_data_retention, poll_interval, timeout, integration)\u001b[0m\n\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         return crawl_module.crawl(\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/methods/crawl.py\u001b[0m in \u001b[0;36mcrawl\u001b[0;34m(client, request, poll_interval, timeout)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Wait for completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     return wait_for_crawl_completion(\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/methods/crawl.py\u001b[0m in \u001b[0;36mwait_for_crawl_completion\u001b[0;34m(client, job_id, poll_interval, timeout)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mcrawl_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_crawl_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# Check if job is complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/methods/crawl.py\u001b[0m in \u001b[0;36mget_crawl_status\u001b[0;34m(client, job_id, pagination_config)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mauto_paginate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpagination_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_paginate\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpagination_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauto_paginate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpagination_config\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpagination_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mpagination_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             documents = _fetch_all_pages(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mresponse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/methods/crawl.py\u001b[0m in \u001b[0;36m_fetch_all_pages\u001b[0;34m(client, next_url, initial_documents, pagination_config)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Fetch next page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/firecrawl/v2/utils/http_client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, endpoint, headers, timeout, retries, backoff_factor)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 response = requests.get(\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Article(BaseModel):\n",
        "    title: str\n",
        "    points: int\n",
        "    by: str\n",
        "    commentsURL: str\n",
        "\n",
        "class TopArticles(BaseModel):\n",
        "    top: List[Article] = Field(..., description=\"Top 5 stories\")\n",
        "\n",
        "# Use JSON format with a Pydantic schema\n",
        "doc = firecrawl.scrape(\n",
        "    \"https://www.geeksforgeeks.org/dsa/dsa-tutorial-learn-data-structures-and-algorithms/\",\n",
        "    formats=[{\"type\": \"json\", \"schema\": TopArticles}],\n",
        ")\n",
        "print(doc.json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEdnkW_BTbj-",
        "outputId": "5a5e8fe7-bfca-49a8-d32f-e1994e76c43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'top': [{'by': 'RishabhPrabhu', 'title': 'DSA Tutorial - Learn Data Structures and Algorithms', 'points': 862, 'commentsURL': 'https://www.geeksforgeeks.org/dsa-tutorial-learn-data-structures-and-algorithms/'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJX1DniaUGtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}